{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类基本思想\n",
    "\n",
    "聚类就是一种寻找数据之间一种内在结构的方法。聚类把全体数据实例组织成一些相似组，而这些相似组被称作聚类。处于相同聚类中的数据实例彼此相同，处于不同聚类中的实例彼此不同。聚类技术通常又被称为无监督学习，因为与监督学习不同，在聚类中那些表示数据类别的分类或者分组信息是没有的。\n",
    "\n",
    "聚类是将数据集中在某些方面具有相似性的数据成员进行分类组织的过程。因此，聚类就是一些数据实例的集合，这个集合中的元素彼此相似，但是它们都与其他聚类中的元素不同。在聚类的相关文献中，一个数据实例有时又被称为对象，因为现实世界中的一个对象可以用数据实例来描述。同时，它有时也被称作数据点(Data Point)，因为我们可以用r 维空间的一个点来表示数据实例，其中r 表示数据的属性个数。\n",
    "\n",
    "![](./img/k-means.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类应用\n",
    "\n",
    "在商业上，聚类分析被用来发现不同的客户群，并且通过购买模式刻画不同的客户群的特征。聚类分析是细分市场的有效工具，同时也可用于研究消费者行为，寻找新的潜在市场、选择实验的市场，并作为多元分析的预处理。在生物上，聚类分析被用来动植物分类和对基因进行分类，获取对种群固有结构的认识。在保险行业上，聚类分析通过一个高的平均消费来鉴定汽车保险单持有者的分组，同时根据住宅类型，价值，地理位置来鉴定一个城市的房产分组。在因特网应用上，聚类分析被用来在网上进行文档归类来修复信息。在电子商务上，聚类分析在电子商务中网站建设数据挖掘中也是很重要的一个方面，通过分组聚类出具有相似浏览行为的客户，并分析客户的共同特征，可以更好的帮助电子商务的用户了解自己的客户，向客户提供更合适的服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类算法\n",
    "\n",
    "典型聚类方法\n",
    "\n",
    "+ 划分聚类(partition clustering): K-means,K-medoids...\n",
    "+ 层次聚类: Birch,ROCK...\n",
    "+ 密度聚类： DBSCAN...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means\n",
    "\n",
    "划分聚类算法是根据给定的n 个对象或者元组的数据集，构建k 个划分聚类的方法。每个划分即为一个聚簇，并且k<n。该方法将数据划分为k 个组，每个组至少有一个对象，每个对象必须属于而且只能属于一个组。1该方法的划分采用按照给定的k 个划分要求，先给出一个初始的划分，然后用迭代重定位技术，通过对象在划分之间的移动来改进划分。\n",
    "\n",
    "为达到划分的全局最优，划分的聚类可能会穷举所有可能的划分。但在实际操作中，往往采用比较流行的k-means 算法或者k-median 算法。\n",
    "\n",
    "k-means 算法最为简单，实现比较容易。每个簇都是使用对象的平均值来表示。\n",
    "\n",
    "1. 将所有对象随机分配到k 个非空的簇中。\n",
    "2. 计算每个簇的平均值，并用该平均值代表相应的值。\n",
    "3. 根据每个对象与各个簇中心的距离，分配给最近的簇。\n",
    "4. 转到步骤二，重新计算每个簇的平均值。这个过程不断重复直到满足某个准则函数或者终止条件。终止(收敛)条件可以是以下任何一个：没有(或者最小数目)数据点被重新分配给不同的聚类;没有(或者最小数目)聚类中心再发生变化;误差平方和(SSE)局部最小。\n",
    "\n",
    "$$SSE=\\sum_{j=1}^{k}\\sum_{x\\in C_j}dis(k,m_j)^2$$\n",
    "\n",
    "其中，$k$表示需要聚集的类的数目， $C_j$表示第$j$ 个聚类，$m_j$表示聚类$C_j$的聚类中心，dist表示数据点$x$ 和聚类中心$m_j$之间的距离。利用该准则可以使所生成的簇尽可能的紧凑和独立。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层次聚类\n",
    "\n",
    "层次聚类主要有两种类型：合并的层次聚类和分裂的层次聚类。前者是一种自底向上的层次聚类算法，从最底层开始，每一次通过合并最相似的聚类来形成上一层次中的聚类，整个当全部数据点都合并到一个聚类的时候停止或者达到某个终止条件而结束，大部分层次聚类都是采用这种方法处理。后者是采用自顶向下的方法，从一个包含全部数据点的聚类开始，然后把根节点分裂为一些子聚类，每个子聚类再递归地继续往下分裂，直到出现只包含一个数据点的单节点聚类出现，即每个聚类中仅包含一个数据点。\n",
    "\n",
    "层次聚类通常被看做成一棵树，其中最小的簇合并在一起创建下一个较高层次的簇，这一层次的簇再合并在一起就创建了再下一层次的簇。通过这样的过程，就可以生成一系列的聚类树来完成聚类。单点聚类处在树的最底层，在树的底层有一个根节点聚类。根节点聚类覆盖了全部数据节点，兄弟节点聚类则划分了它们共同的父节点中的所有的数据点。\n",
    "\n",
    "![](./img/clustering-hir.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## DBSCAN\n",
    " \n",
    "DBSCAN（Density-Based Spatial Clustering of Applications with Noise）聚类算法，它是一种基于高密度连通区域的、基于密度的聚类算法，能够将具有足够高密度的区域划分为簇，并在具有噪声的数据中发现任意形状的簇。我们总结一下DBSCAN聚类算法原理的基本要点：\n",
    "\n",
    "+ DBSCAN算法需要选择一种距离度量，对于待聚类的数据集中，任意两个点之间的距离，反映了点之间的密度，说明了点与点是否能够聚到同一类中。由于DBSCAN算法对高维数据定义密度很困难，所以对于二维空间中的点，可以使用欧几里德距离来进行度量。\n",
    "+ DBSCAN算法需要用户输入2个参数：一个参数是半径（Eps），表示以给定点P为中心的圆形邻域的范围；另一个参数是以点P为中心的邻域内最少点的数量（MinPts）。如果满足：以点P为中心、半径为Eps的邻域内的点的个数不少于MinPts，则称点P为核心点。\n",
    "+ DBSCAN聚类使用到一个k-距离的概念，k-距离是指：给定数据集P={p(i); i=0,1,…n}，对于任意点P(i)，计算点P(i)到集合D的子集S={p(1), p(2), …, p(i-1), p(i+1), …, p(n)}中所有点之间的距离，距离按照从小到大的顺序排序，假设排序后的距离集合为D={d(1), d(2), …, d(k-1), d(k), d(k+1), …,d(n)}，则d(k)就被称为k-距离。也就是说，k-距离是点p(i)到所有点（除了p(i)点）之间距离第k近的距离。对待聚类集合中每个点p(i)都计算k-距离，最后得到所有点的k-距离集合E={e(1), e(2), …, e(n)}。\n",
    "+ 根据经验计算半径Eps：根据得到的所有点的k-距离集合E，对集合E进行升序排序后得到k-距离集合E’，需要拟合一条排序后的E’集合中k-距离的变化曲线图，然后绘出曲线，通过观察，将急剧发生变化的位置所对应的k-距离的值，确定为半径Eps的值。\n",
    "+ 根据经验计算最少点的数量MinPts：确定MinPts的大小，实际上也是确定k-距离中k的值，DBSCAN算法取k=4，则MinPts=4。\n",
    "+ 另外，如果觉得经验值聚类的结果不满意，可以适当调整Eps和MinPts的值，经过多次迭代计算对比，选择最合适的参数值。可以看出，如果MinPts不变，Eps取得值过大，会导致大多数点都聚到同一个簇中，Eps过小，会导致已一个簇的分裂；如果Eps不变，MinPts的值取得过大，会导致同一个簇中点被标记为噪声点，MinPts过小，会导致发现大量的核心点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 聚类评估\n",
    "\n",
    "其中一种评估方法为轮廓系数（Silhouette Coefficient），它结合了聚类的凝聚度（Cohesion）和分离度（Separation），用于评估聚类的效果。该值处于-1~1之间，值越大，表示聚类效果越好。具体计算方法如下：\n",
    "\n",
    "1. 对于第i个元素$x_i$，计算$x_i$与其同一个簇内的所有其他元素距离的平均值，记作$a_i$，用于量化簇内的凝聚度。\n",
    "2. 选取$x_i$外的一个簇$b$，计算$x_i$与$b$中所有点的平均距离，遍历所有其他簇，找到最近的这个平均距离,记作$b_i$，用于量化簇之间分离度。\n",
    "3. 对于元素$x_i$，轮廓系数$s_i = (b_i – a_i)/max(a_i,b_i)$\n",
    "4. 计算所有$x$的轮廓系数，求出平均值即为当前聚类的整体轮廓系数\n",
    "\n",
    "我们不难发现若$s_i$小于0，说明$x_i$与其簇内元素的平均距离小于最近的其他簇，表示聚类效果不好。如果$a_i$趋于0，或者$b_i$足够大，那么$s_i$趋近与1，说明聚类效果比较好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
