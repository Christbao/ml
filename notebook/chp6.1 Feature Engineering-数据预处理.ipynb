{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理常用方法\n",
    "\n",
    "+ 数据标准化\n",
    "+ 数据最大最小缩放处理\n",
    "+ 正则化/归一化\n",
    "+ 特征二值化\n",
    "+ 数据缺失值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础知识\n",
    "\n",
    "均值\n",
    "\n",
    "$$\\bar{x}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}$$\n",
    "\n",
    "方差\n",
    "\n",
    "$$s^{2}=\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{2}$$\n",
    "\n",
    "0范数：向量中非零元素的个数\n",
    "\n",
    "1范数\n",
    "\n",
    "$$||X||=\\sum_{i=1}^{n}|x_{i}|$$\n",
    "\n",
    "2范数\n",
    "\n",
    "$$||X||_{2}=(\\sum_{i=1}^{n}x_{i}^{2})^{\\frac{1}{2}}$$\n",
    "\n",
    "p范数\n",
    "\n",
    "$$||X||_{p}=(\\sum_{i=1}^{n}x_{i}^{p})^{\\frac{1}{p}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据标准化\n",
    "\n",
    "公式为：(X-X_mean)/X_std 计算时对每个属性/每列分别进行.\n",
    "\n",
    "将数据按其属性(按列进行)减去其均值，然后除以其方差。最后得到的结果是，对每个属性/每列来说所有数据都聚集在0附近，方差值为1。当单个特征的样本取值相差甚大或明显不遵从高斯正态分布时，标准化表现的效果较差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing   \n",
    "import numpy as np  \n",
    "X = np.array([[ 1., -1.,  2.],  \n",
    "              [ 2.,  0.,  0.],  \n",
    "              [ 0.,  1., -1.]])  \n",
    "#用来计算数据X每个特征的均值 \n",
    "X_mean = X.mean(axis=0)  \n",
    "X_std = X.std(axis=0)  \n",
    "X1 = (X-X_mean)/X_std  \n",
    "#axis：int类型，初始值为0，axis用来计算均值 means 和标准方差 standard + deviations.\n",
    "#如果是0，则单独的标准化每个特征（列），如果是1，则标准化每个观测样本（行）。\n",
    "#with_mean: boolean类型，默认为True，表示将数据均值规范到0\n",
    "#with_std: boolean类型，默认为True，表示将数据方差规范到1\n",
    "X_scale = preprocessing.scale(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing   \n",
    "import numpy as np  \n",
    "X = np.array([[ 1., -1.,  2.],  \n",
    "              [ 2.,  0.,  0.],  \n",
    "              [ 0.,  1., -1.]])  \n",
    "scaler = preprocessing.StandardScaler()  \n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "将属性缩放到一个指定的最大值和最小值(通常是1-0)之间，这可以通过preprocessing.MinMaxScaler类来实现。\n",
    "\n",
    "使用这种方法的目的包括：\n",
    "\n",
    "+ 对于方差非常小的属性可以增强其稳定性；\n",
    "+ 维持稀疏矩阵中为0的条目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.        ,  1.        ],\n",
       "       [ 1.        ,  0.5       ,  0.33333333],\n",
       "       [ 0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing   \n",
    "import numpy as np  \n",
    "X = np.array([[ 1., -1.,  2.],  \n",
    "              [ 2.,  0.,  0.],  \n",
    "              [ 0.,  1., -1.]])  \n",
    "min_max_scaler = preprocessing.MinMaxScaler() #也可以直接指定最大最小值的范围：feature_range=(min, max) \n",
    "X_minMax = min_max_scaler.fit_transform(X)\n",
    "X_minMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5       ,  0.        ,  1.66666667]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[ -3., -1.,  4.]])  \n",
    "X_test_minmax = min_max_scaler.transform(X_test)  \n",
    "X_test_minmax  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化(Normalization)\n",
    "\n",
    "正则化的过程是将每个样本缩放到单位范数(每个样本的范数为1)，如果要使用如二次型(点积)或者其它核方法计算两个样本之间的相似性这个方法会很有用。\n",
    "Normalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数(l1-norm,l2-norm)等于1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]  \n",
    "X_normalized = preprocessing.normalize(X, norm='l2')  \n",
    "X_normalized                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二值化(Binarization)\n",
    "\n",
    "特征的二值化主要是为了将数据特征转变成boolean变量。在sklearn中，sklearn.preprocessing.Binarizer函数可以实现这一功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]  \n",
    "binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing  \n",
    "binarizer\n",
    "binarizer.transform(X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarizer函数也可以设定一个阈值，结果数据值大于阈值的为1，小于阈值的为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer(threshold=1.1)\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值处理\n",
    "\n",
    "由于不同的原因，许多现实中的数据集都包含有缺失值，要么是空白的，要么使用NaNs或者其它的符号替代。这些数据无法直接使用scikit-learn分类器直接训练，所以需要进行处理。幸运地是，sklearn中的Imputer类提供了一些基本的方法来处理缺失值，如使用均值、中位值或者缺失值所在列中频繁出现的值来替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.          2.        ]\n",
      " [ 6.          3.66666667]\n",
      " [ 7.          6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from sklearn.preprocessing import Imputer  \n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)  \n",
    "imp.fit([[1, 2], [np.nan, 3], [7, 6]])  \n",
    "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)  \n",
    "X = [[np.nan, 2], [6, np.nan], [7, 6]]  \n",
    "print(imp.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "稀疏矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.          2.        ]\n",
      " [ 6.          3.66666667]\n",
      " [ 7.          6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp  \n",
    "X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])  \n",
    "imp = Imputer(missing_values=0, strategy='mean', axis=0)  \n",
    "imp.fit(X)  \n",
    "Imputer(axis=0, copy=True, missing_values=0, strategy='mean', verbose=0)  \n",
    "X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])  \n",
    "print(imp.transform(X_test))                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot编码\n",
    "\n",
    "在很多机器学习任务中，特征并不总是连续值，而有可能是分类值。\n",
    "\n",
    "例如，考虑一下的三个特征：\n",
    "\n",
    "    [\"male\", \"female\"]\n",
    "\n",
    "    [\"from Europe\", \"from US\", \"from Asia\"]\n",
    "\n",
    "    [\"uses Firefox\", \"uses Chrome\", \"uses Safari\", \"uses Internet Explorer\"]\n",
    "\n",
    "如果将上述特征用数字表示，效率会高很多。例如：\n",
    "\n",
    "    [\"male\", \"from US\", \"uses Internet Explorer\"] 表示为[0, 1, 3]\n",
    "\n",
    "    [\"female\", \"from Asia\", \"uses Chrome\"]表示为[1, 2, 1]\n",
    "\n",
    "\n",
    "但是，即使转化为数字表示后，上述数据也不能直接用在我们的分类器中。因为，分类器往往默认数据数据是连续的，并且是有序的。但是，按照我们上述的表示，数字并不是有序的，而是随机分配的。为了解决上述问题，其中一种可能的解决方法是采用独热编码（One-Hot Encoding）\n",
    "\n",
    "假如只有一个特征是离散值：\n",
    "\n",
    "　　　　{sex：{male， female，other}}\n",
    "\n",
    "　　该特征总共有3个不同的分类值，此时需要3个bit位表示该特征是什么值，对应bit位为1的位置对应原来的特征的值（一般情况下可以将原始的特征的取值进行排序，以便于后期使用），此时得到独热码为{100}男性 ，{010}女性，{001}其他\n",
    "\n",
    "　　假如多个特征需要独热码编码，那么久按照上面的方法依次将每个特征的独热码拼接起来：\n",
    "\n",
    "　　　　{sex：{male， female，other}}\n",
    "\n",
    "　　　　{grade：{一年级， 二年级，三年级， 四年级}}\n",
    "\n",
    "　　此时对于输入为{sex：male； grade： 四年级}进行独热编码，可以首先将sex按照上面的进行编码得到{100}，然后按照grade进行编码为{0001}，那么两者连接起来得到最后的独热码{1000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([[0, 1, 3]]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多项式变换-PolynomialFeatures \n",
    "\n",
    "对于4个feature, 度为2的特征$(x_1,x_2,x_3,x_4)$的多项式变换为$(1,x_1,x_2,x_3,x_4,x_1^2,x_1*x_2,x_1*x_3,x_1*x_4,x_2^2,x_2*x_3,x_2*x_4,x_3^2,x_3*x_4,x_4^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   2.,   3.,   4.,   1.,   2.,   3.,   4.,   4.,   6.,\n",
       "          8.,   9.,  12.,  16.],\n",
       "       [  1.,   1.,   2.,   3.,   4.,   1.,   2.,   3.,   4.,   4.,   6.,\n",
       "          8.,   9.,  12.,  16.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#多项式转换,参数degree为度，默认值为2\n",
    "X=[[1,2,3,4],\n",
    "   [1,2,3,4]]\n",
    "PolynomialFeatures().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数变换\n",
    "\n",
    "基于单变量函数的数据变换可以使用一个统一的方式完成，使用preproccessing库的FunctionTransformer对数据进行对数函数转换的代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69314718,  1.09861229,  1.38629436,  1.60943791],\n",
       "       [ 0.69314718,  1.09861229,  1.38629436,  1.60943791]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import log1p\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "#自定义转换函数为对数函数的数据变换\n",
    "#第一个参数是单变元函数\n",
    "FunctionTransformer(log1p).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "|类 |说明|\n",
    "|:---:|:---:|\n",
    "|StandardScaler  |\t标准化，基于特征矩阵的列，将特征值转换至服从标准正态分布\n",
    "|MinMaxScaler |\t区间缩放，基于最大最小值，将特征值转换到[0, 1]区间上\n",
    "|Normalizer |\t基于特征矩阵的行，将样本向量转换为“单位向量”\n",
    "|Binarizer  |\t基于给定阈值，将定量特征按阈值划分\n",
    "|OneHotEncoder|\t将定性数据编码为定量数据\n",
    "|Imputer |\t计算缺失值，缺失值可填充为均值等\n",
    "|PolynomialFeatures  |\t多项式数据转换\n",
    "|FunctionTransformer |\t使用单变量的函数来转换数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
